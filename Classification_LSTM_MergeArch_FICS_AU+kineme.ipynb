{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aVOOrhnd_scD"
   },
   "outputs": [],
   "source": [
    "#import required modules\n",
    "#basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn for required metrics\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#tensorflow and other imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#importing keras layers and models as required\n",
    "from keras.layers import merge\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding of kineme sequence\n",
    "def onehot_encoding(ks, nKineme):\n",
    "    onehot_encoded = list()\n",
    "    for k in ks:\n",
    "        vec = [0 for _ in range(nKineme)]\n",
    "        vec[k-1] = 1\n",
    "        onehot_encoded.append(vec)\n",
    "    return onehot_encoded\n",
    "\n",
    "\n",
    "def ks_encoding(ks, nKineme):\n",
    "    # ks is a numpy ndarray\n",
    "    m, n = ks.shape \n",
    "    ks = ks.tolist() \n",
    "    encoded_features = np.asarray(\n",
    "        [np.asarray(onehot_encoding(ks[i], nKineme)) for i in range(m)]\n",
    "    )\n",
    "    return encoded_features\n",
    "\n",
    "#function to convert continous labels into binary labels\n",
    "def bin_labels(data_rec):             \n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    median_value = np.median(data_rec)\n",
    "    for it in range(0,len(data_rec),1):\n",
    "        if data_rec[it]<=median_value :\n",
    "            count_0 += 1\n",
    "            data_rec[it]=0\n",
    "        else:\n",
    "            count_1 += 1\n",
    "            data_rec[it]=1\n",
    "    print(count_0, count_1)\n",
    "    return data_rec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#define path for the training, testing and validation labels and data for the label Opneness of the FICS dataset\n",
    "y_train_path = 'Kinemes/train_O.npy'\n",
    "X_train_path = 'Kinemes/train_kineme_5990.npy'\n",
    "y_test_path = 'Kinemes/test_O.npy'\n",
    "X_test_path = 'Kinemes/test_kineme_1997.npy'\n",
    "y_val_path = 'Kinemes/val_O.npy'\n",
    "X_val_path = 'Kinemes/val_kineme_1995.npy'\n",
    "#pass the above data paths as arguments to the training lstm function\n",
    "training_lstm(y_train_path, X_train_path, y_test_path, X_test_path, y_val_path, X_val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "96RR0LGd3Xa1"
   },
   "outputs": [],
   "source": [
    "def training_lstm(y_train_path, X_train_path, y_test_path, X_test_path, y_val_path, X_val_path):\n",
    "    # parameters\n",
    "    #sequence length for FICS dataset is 14 for all videos\n",
    "    nKineme, seqLen, nClass = 16, 14, 2\n",
    "    nAction = 17\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "    nNeuron = 32\n",
    "\n",
    "    #load all the data and label files and convert the labels to 0 or 1 depending on the median\n",
    "    y_train = np.load(y_train_path)\n",
    "    y_train = y_train[:,1].astype(np.float)\n",
    "    y_train = bin_labels(y_train)\n",
    "    train_mat = np.load(X_train_path)\n",
    "    y_test = np.load(y_test_path)\n",
    "    y_test = y_test[:,1].astype(np.float)\n",
    "    y_test = bin_labels(y_test)\n",
    "    test_mat = np.load(X_test_path)\n",
    "    y_val = np.load(y_val_path)\n",
    "    y_val = y_val[:,1].astype(np.float)\n",
    "    y_val = bin_labels(y_val)\n",
    "    val_mat = np.load(X_val_path)\n",
    "    \n",
    "\n",
    "\n",
    "    #Model architecture with different layers\n",
    "\n",
    "    #Using two different lstm layers for the kineme and action unit data separately and concatenating them at the end\n",
    "    #kineme lstm implementation; input is the encoding of kineme sequence of 16 and 14 is teh time step for each file; sequence of kinemes from each file\n",
    "    #we provide the input shape to a lstm layer with activation\n",
    "    left_branch_input = Input(shape=(seqLen,nKineme), name='Left_input')\n",
    "    left_branch_output = LSTM(32, activation='relu')(left_branch_input)\n",
    "\n",
    "    #in right side, we have action units as the input sequences with each as a 17 dimensional vector\n",
    "    right_branch_input = Input(shape=(seqLen,nAction), name='Right_input')\n",
    "    right_branch_output = LSTM(32, activation='relu')(right_branch_input)\n",
    "\n",
    "    #merging the two layers using a dense layer and then having one final output layer and the optimizer, compile and summary\n",
    "    merged = concatenate([left_branch_output, right_branch_output], name='Concatenate')\n",
    "    final_model_output = Dense(2, activation='sigmoid')(merged)\n",
    "    final_model = Model(inputs=[left_branch_input, right_branch_input], outputs=final_model_output,\n",
    "                        name='Final_output')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    final_model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    final_model.summary()\n",
    "\n",
    "\n",
    "    #define the loss and accuracy lists\n",
    "    test_loss=[]\n",
    "    test_acc=[]\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    fi_weighted=[]\n",
    "    fi_macro=[]\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    #passing the features and labels data to their respective variables as train, test or validation\n",
    "    train_features,  train_labels = train_mat, y_train\n",
    "    test_features,  test_labels = test_mat, y_test\n",
    "    val_features,  val_labels = val_mat, y_val\n",
    "    \n",
    "    #extract the kinemes and convert each value to the encoding using the ks_encoding method\n",
    "    #do the same for train, test and validation data\n",
    "    train_kinemes = ks_encoding(train_features[:,0:seqLen], nKineme)\n",
    "    test_kinemes = ks_encoding(test_features[:,0:seqLen], nKineme)\n",
    "    val_kinemes = ks_encoding(val_features[:,0:seqLen], nKineme)\n",
    "    \n",
    "    #extract the remaining values for action units\n",
    "    train_action = train_features[:, seqLen:]\n",
    "    test_action = test_features[:, seqLen:]\n",
    "    val_action = val_features[:, seqLen:]\n",
    "    \n",
    "    #reshape the action unit to a 3d matrix, similar to that of kinemes\n",
    "    train_aus = train_action.reshape((train_action.shape[0], seqLen, nAction))\n",
    "    test_aus = test_action.reshape((test_action.shape[0], seqLen, nAction))\n",
    "    val_aus = val_action.reshape((val_action.shape[0], seqLen, nAction))\n",
    "    \n",
    "    # convert labels into categorical\n",
    "    train_labels = to_categorical(train_labels)   \n",
    "    val_labels = to_categorical(val_labels)  \n",
    "    \n",
    "    #model training y passing both kineme and AU data along with the training labels\n",
    "    zero_bias_history = Model.fit([train_kinemes, train_aus], train_labels, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data=([val_kinemes, val_aus], val_labels), callbacks=[callback]) \n",
    "    #evaluate the model using the test data\n",
    "    score = Model.evaluate([test_kinemes, test_aus], to_categorical(test_labels), verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    #append the test, train and val accuracy to the above lists\n",
    "    test_loss.append(score[0])\n",
    "    test_acc.append(score[1])\n",
    "    train_acc.append(np.array(zero_bias_history.history['accuracy']).mean())\n",
    "    val_acc.append(np.array(zero_bias_history.history['val_accuracy']).mean())\n",
    "    \n",
    "    #find the prediction values that will be used for finding the f1 score \n",
    "    y_testpred = Model.predict_classes([test_kinemes, test_aus])\n",
    "    f1_w_epoch = f1_score(test_labels, y_testpred, average='weighted')\n",
    "    f1_m_epoch = f1_score(test_labels, y_testpred, average='macro')\n",
    "    fi_weighted.append(f1_w_epoch)\n",
    "    fi_macro.append(f1_m_epoch)\n",
    "\n",
    "\n",
    "    #print the accuracies and F1 scores\n",
    "    print(\"For:\" + str(Label_class))\n",
    "    print(\"Train_accuracy {0}±{1}\".format(round(np.array(train_acc).mean(),3),round(np.array(train_acc).std(),3)))\n",
    "    print(\"Test_accuracy {0}±{1}\".format(round(np.array(test_acc).mean(),3),round(np.array(test_acc).std(),3)))\n",
    "    print(\"F1_Weighted {0}±{1}\".format(round(np.array(fi_weighted).mean(),3),round(np.array(fi_weighted).std(),3)))\n",
    "    print(\"F1_Macro {0}±{1}\".format(round(np.array(fi_macro).mean(),3),round(np.array(fi_macro).std(),3)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iqINmounriSv",
    "gYfIUsPgrrTM",
    "vS96QElerxa_",
    "e_lBNFo-spRs"
   ],
   "name": "Copy of LSTM_kineme_CHUNKS.ipynb",
   "provenance": [
    {
     "file_id": "1KZ-dQBY0j7q1d8fvPbbX1J0v8jqY0Gly",
     "timestamp": 1618116554520
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
